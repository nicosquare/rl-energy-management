{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.utils.tools import set_all_seeds, load_config,plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "#\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "all_states_za, all_rewards_za, all_actions_za, all_net_energy_za = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(2):\n",
    "\n",
    "    states_za, rewards_za, actions_za= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_za.append(state_0)\n",
    "    rewards_za.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.zeros((config['env']['batch_size'], 1))\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_za.append(s_t)\n",
    "        rewards_za.append(r_t)\n",
    "        actions_za.append(action)\n",
    "\n",
    "    all_states_za.append(np.array(states_za))\n",
    "    all_rewards_za.append(np.array(rewards_za))\n",
    "    all_actions_za.append(np.array(actions_za))\n",
    "    all_net_energy_za.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_za, all_rewards_za, all_actions_za, all_net_energy_za, 'Zero Agent (Family)', save=True, filename='imgs/za_family.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "all_states_ra, all_rewards_ra, all_actions_ra, all_net_energy_ra = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    states_ra, rewards_ra, actions_ra= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_ra.append(state_0)\n",
    "    rewards_ra.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.random.uniform(low=-1, high=1, size=(config['env']['batch_size'], 1))\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_ra.append(s_t)\n",
    "        rewards_ra.append(r_t)\n",
    "        actions_ra.append(action)\n",
    "\n",
    "    all_states_ra.append(np.array(states_ra))\n",
    "    all_rewards_ra.append(np.array(rewards_ra))\n",
    "    all_actions_ra.append(np.array(actions_ra))\n",
    "    all_net_energy_ra.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_ra, all_rewards_ra, all_actions_ra, all_net_energy_ra, 'Random Agent (Family)', save=True, filename='imgs/ra_family.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVX Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "perf_actions_family = [\n",
    "    0.26258278,  0.11611298,  0.07428618,  0.07643896,  0.12529734,\n",
    "    0.23417065, -0.18023179, -0.7086571 ,  0.18634816,  0.60601339,\n",
    "    -0.24662803, -0.08707155, -0.07357717, -0.18069343,  0.58562932,\n",
    "    0.09886819, -0.20698431, -0.48973657,  0.14986115,  0.01168165,\n",
    "    -0.05987804, -0.05891896, -0.08977367, -0.14514013\n",
    "]\n",
    "\n",
    "perf_actions = perf_actions_family\n",
    "\n",
    "all_states_opt, all_rewards_opt, all_actions_opt, all_net_energy_opt = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(2):\n",
    "\n",
    "    states_opt, rewards_opt, actions_opt= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_opt.append(state_0)\n",
    "    rewards_opt.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.ones((config['env']['batch_size'], 1))\n",
    "        action = action * perf_actions[env.mg.current_step]\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_opt.append(s_t)\n",
    "        rewards_opt.append(r_t)\n",
    "        actions_opt.append(action)\n",
    "\n",
    "    all_states_opt.append(states_opt)\n",
    "    all_rewards_opt.append(rewards_opt)\n",
    "    all_actions_opt.append(actions_opt)\n",
    "    all_net_energy_opt.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_opt, all_rewards_opt, all_actions_opt, all_net_energy_opt, 'CVX Agent (Family)', save=True, filename='imgs/cvx_family.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C Causality cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.a2c.c_mg_simple import Agent\n",
    "\n",
    "try:\n",
    "    config = load_config(\"c_a2c\")\n",
    "    config = config['train']\n",
    "    \n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C C (Family) results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C C (Teenagers) results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PG disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.pg.d_mg_simple import Agent\n",
    "\n",
    "# Start wandb logger\n",
    "\n",
    "try:\n",
    "\n",
    "    config = load_config(\"d_pg\")\n",
    "    config = config['train']\n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results (Family) with noise', save=True, filename='imgs/d_pg_results_family_n.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results', save=False, filename='a2c_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results', save=False, filename='a2c_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C Causality disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.a2c.d_mg_simple import Agent\n",
    "\n",
    "# Start wandb logger\n",
    "\n",
    "try:\n",
    "    config = load_config(\"d_a2c\")\n",
    "    config = config['train']\n",
    "\n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D results (Family) without noise', save=True, filename='imgs/d_a2c_results_family_nn.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Home Business)\n",
    "\n",
    "print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D Home Business results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D results', save=False, filename='a2c_results.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bcte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4360e16d43ac692103fa28bcc8d0bd7c33534b35175524cb6d3ea499dda18b7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
