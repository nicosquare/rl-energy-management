{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profile': 'family', 'battery': {'random_soc_0': False, 'capacity': 1, 'efficiency': 0.9}, 'pv': {'nominal_power': 1}}\n",
      "{'profile': 'teenagers', 'battery': {'random_soc_0': False, 'capacity': 1, 'efficiency': 0.9}, 'pv': {'nominal_power': 1}}\n"
     ]
    }
   ],
   "source": [
    "from src.utils.tools import set_all_seeds, load_config, plot_results\n",
    "\n",
    "config = load_config(\"d_a2c_2h\")\n",
    "config = config[\"train\"][\"env\"][\"houses\"]\n",
    "for uid, attr in zip(config, config.values()):\n",
    "    # print(uid, attr)\n",
    "    if \"pv\" in attr:\n",
    "        print(attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.utils.tools import set_all_seeds, load_config, plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "#\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "all_states_za, all_rewards_za, all_actions_za, all_net_energy_za = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(2):\n",
    "\n",
    "    states_za, rewards_za, actions_za= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_za.append(state_0)\n",
    "    rewards_za.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.zeros((config['env']['batch_size'], 1))\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_za.append(s_t)\n",
    "        rewards_za.append(r_t)\n",
    "        actions_za.append(action)\n",
    "\n",
    "    all_states_za.append(np.array(states_za))\n",
    "    all_rewards_za.append(np.array(rewards_za))\n",
    "    all_actions_za.append(np.array(actions_za))\n",
    "    all_net_energy_za.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_za, all_rewards_za, all_actions_za, all_net_energy_za, 'Zero Agent (Family)', save=True, filename='imgs/za_family.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "all_states_ra, all_rewards_ra, all_actions_ra, all_net_energy_ra = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    states_ra, rewards_ra, actions_ra= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_ra.append(state_0)\n",
    "    rewards_ra.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.random.uniform(low=-1, high=1, size=(config['env']['batch_size'], 1))\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_ra.append(s_t)\n",
    "        rewards_ra.append(r_t)\n",
    "        actions_ra.append(action)\n",
    "\n",
    "    all_states_ra.append(np.array(states_ra))\n",
    "    all_rewards_ra.append(np.array(rewards_ra))\n",
    "    all_actions_ra.append(np.array(actions_ra))\n",
    "    all_net_energy_ra.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_ra, all_rewards_ra, all_actions_ra, all_net_energy_ra, 'Random Agent (Family)', save=True, filename='imgs/ra_family.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVX Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)\n",
    "\n",
    "config = load_config(\"zero\")\n",
    "config = config['train']\n",
    "env = MGSimple(config=config['env'])\n",
    "\n",
    "perf_actions_family = [\n",
    "    0.26258278,  0.11611298,  0.07428618,  0.07643896,  0.12529734,\n",
    "    0.23417065, -0.18023179, -0.7086571 ,  0.18634816,  0.60601339,\n",
    "    -0.24662803, -0.08707155, -0.07357717, -0.18069343,  0.58562932,\n",
    "    0.09886819, -0.20698431, -0.48973657,  0.14986115,  0.01168165,\n",
    "    -0.05987804, -0.05891896, -0.08977367, -0.14514013\n",
    "]\n",
    "\n",
    "\n",
    "perf_actions_teenagers= [\n",
    "    0.28240224,  0.09228588,  0.00384631, -0.05298454, -0.08100985,\n",
    "    -0.06272698, -0.18181306,  0.06912068,  0.29745927,  0.49490228,\n",
    "    -0.2622285 , -0.02862169,  0.08349623,  0.0791313 ,  0.15562932,\n",
    "    -0.03779848, -0.27253987, -0.55529212,  0.27457264,  0.09677589,\n",
    "    0.02021528, -0.01926573, -0.08844495, -0.30711156\n",
    "]\n",
    "\n",
    "\n",
    "perf_actions_home_business = [\n",
    "    0.28148607,  0.11100254,  0.05643912,  0.05804768,  0.11544059,\n",
    "    0.2664729 , -0.03324662, -0.7086571 , -0.14698517,  0.16156894,\n",
    "    0.13414224,  0.16450093,  0.16208893,  0.12540297,  0.14118488,\n",
    "    -0.19890959, -0.46920654, -0.22077276,  0.27334051,  0.09539245,\n",
    "    0.02146734, -0.00132075, -0.1344098 , -0.25446975\n",
    "]\n",
    "\n",
    "perf_actions = perf_actions_home_business\n",
    "\n",
    "all_states_opt, all_rewards_opt, all_actions_opt, all_net_energy_opt = [], [], [], []\n",
    "\n",
    "# Just a couple iterations to generate the line\n",
    "\n",
    "for _ in range(2):\n",
    "\n",
    "    states_opt, rewards_opt, actions_opt= [], [], []\n",
    "    \n",
    "    # Initialize states and rewards\n",
    "\n",
    "    state_0, r_0, done, _ = env.reset()\n",
    "\n",
    "    states_opt.append(state_0)\n",
    "    rewards_opt.append(r_0)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action = np.ones((config['env']['batch_size'], 1))\n",
    "        action = action * perf_actions[env.mg.current_step]\n",
    "\n",
    "        s_t, r_t, done, _ = env.step(action)\n",
    "\n",
    "        states_opt.append(s_t)\n",
    "        rewards_opt.append(r_t)\n",
    "        actions_opt.append(action)\n",
    "\n",
    "    all_states_opt.append(states_opt)\n",
    "    all_rewards_opt.append(rewards_opt)\n",
    "    all_actions_opt.append(actions_opt)\n",
    "    all_net_energy_opt.append(env.mg.net_energy)\n",
    "\n",
    "plot_results(env, all_states_opt, all_rewards_opt, all_actions_opt, all_net_energy_opt, 'CVX Agent (Business)', save=True, filename='imgs/cvx_business.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C Causality cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.a2c.c_mg_simple import Agent\n",
    "\n",
    "try:\n",
    "    config = load_config(\"c_a2c\")\n",
    "    config = config['train']\n",
    "    \n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C C (Family) results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C C (Teenagers) results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PG disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.pg.d_mg_simple import Agent\n",
    "\n",
    "# Start wandb logger\n",
    "\n",
    "try:\n",
    "\n",
    "    config = load_config(\"d_pg\")\n",
    "    config = config['train']\n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results (Family) with noise', save=True, filename='imgs/d_pg_results_family_n.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results', save=False, filename='a2c_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'PG D results', save=False, filename='a2c_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C Causality disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "from src.environments.mg_simple import MGSimple\n",
    "from src.rl.a2c.d_mg_simple import Agent\n",
    "\n",
    "# Start wandb logger\n",
    "\n",
    "try:\n",
    "    config = load_config(\"d_a2c\")\n",
    "    config = config['train']\n",
    "\n",
    "    '''\n",
    "        Run the simulator\n",
    "    '''\n",
    "\n",
    "    set_all_seeds(0)\n",
    "\n",
    "    # Instantiate the environment\n",
    "\n",
    "    my_env = MGSimple(config=config['env'])\n",
    "\n",
    "    # Instantiate the agent\n",
    "\n",
    "    agent = Agent(\n",
    "        env=my_env, config = config\n",
    "    )\n",
    "\n",
    "    # Launch the training\n",
    "\n",
    "    all_states, all_rewards, all_actions, all_net_energy = agent.train()\n",
    "\n",
    "    # Finish Wandb execution\n",
    "\n",
    "    agent.wdb_logger.finish()\n",
    "\n",
    "except (RuntimeError, KeyboardInterrupt):\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Family)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D results (Family) without noise', save=True, filename='imgs/d_a2c_results_family_nn.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Home Business)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D Home Business results', save=False, filename='a2c_results.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results (Teenagers)\n",
    "\n",
    "# print(wdb_config)\n",
    "\n",
    "plot_results(my_env, all_states, all_rewards, all_actions, all_net_energy, 'A2C D results', save=False, filename='a2c_results.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bcte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4360e16d43ac692103fa28bcc8d0bd7c33534b35175524cb6d3ea499dda18b7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
